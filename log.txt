3/31 -
The IsWindowVisible function also counts windows on the taskbar, as visible. 
The EnumWindows function takes a function as an argument. This function is also known as callback function because it's being passed in as an argument. 
The window handle (win_handle, in my case) is supposed to be a special identifier/reference used by the operating system to keep track of the window. These handles is said to be represented usually by an integer by the OS. 

The EnumWindows function, in this case, contains two arguments. One is the callback function and the second is supposed to be the list argument required by the callback function since my callback takes two arguments.
EnumWindows iterates through each window on the computer and will pass the handle of the window to the callback function when it encounters a window. Because callback appends the title to a list, it will append it to the window_titles list provided by the EnumWindows function. 

The OpenCV's imshow() function takes two parameters (first being the title, second being the screenshot itself as a NumPy array) and displays the screenshot 
waitKey() waits for a key to be pressed, will still close the window without the destroyAllWindows() function
destroyAllWindows() function is used still, just in the case that a OpenCV window remains open after being closed. It also closes ALL OpenCV windows. 

4/7 - 
Plan: use template images, seek for the patch/area where it lies in screenshot, ask for position of where the match is found, save the positions by assigning them to variables that will be the cards/buttons, assign positions after template images are matched  

if scales aren’t the same, scale the template image  

After getting the positions of everything, I can check each position for a specific string that contains the name of a unit I passed in for the user input 

Receive coordinates for skill buttons, save them (by assigning them to a class or by unit 1, 2, 3), can have user input who is in those unit slots. For swap scenarios, can make more unit slots to hold those units, look for mystic code position and its skills. 
For NP gauge check, find the position coordinates of the gauge for all three units and just have user tell us which unit's gauge to check for.

Currently:
The PyAutoGUI library seems to only interact with the user's cursor. 
The easiest way for this code to play the game is to just assign it coordinates based on my monitor, and have it click there.
Might consider/look into a way to create a second cursor that will operate on its own rather than using my cursor. 
Need to fix template matching
look into pydirectinput library

4/8 - 
* unpacks iterable objects like lists, tuples, sets into separate arguments when calling a function

How to send a click event to a window without it moving user's cursor
https://stackoverflow.com/questions/59285854/is-there-a-way-to-send-a-click-event-to-a-window-in-the-background-in-python

The s1 image is a screenshot image taken in the same scale as the LDPlayer client and is detected. 67 x 68 pixels
The 45 x 45 pixels castoria_skill1 image isn't detected. Scaling seems to matter

Reminders:
ctrl + k + c is multi-line comments
ctrl + k + u removes multi-line comments
shift + alt + a adds/removes block comments

4/10 -
Tried feature based matching. It does not seem to detect the corners of the skill buttons in the screenshot. 

reminder:
use template images, seek for the patch/area where it lies in screenshot, ask for position of where the match is found, save the positions by assigning them to variables that will be the cards/buttons, assign positions after template images are matched  

if scales aren’t the same, scale the template image  

After getting the positions of everything, I can check each position for a specific string that contains the 
name of a unit I passed in for the user input 

4/11 -
Coordinates for skills:
Charisma Icon: [(37, 553), (343, 553), (344, 553)]
NP Charge Icon: [(121, 553), (122, 553), (428, 553), (819, 553)]
Arts Up Icon: [(207, 552), (513, 552), (514, 552), (649, 552), (650, 552)]

4/12 - 
New idea: try scaling the screenshot by 2x to see if feature based registration can find the corners of the skills 

4/15 - 
Create a case where resolution of emulator is constant and another case where it isn't so we have to find everything


4/18 -
To allow user input in the output of VSCode, do Control + , and look for code runner run in terminal and check it on

4/19 -
Need to check for which units to target for skills 
Detect cards (mainly for NP)
Tap screen to speed up and skip, or wait till loaded
Implement mystic code detect and swap
Tap and repeat


# Feature based registration
def detect_corners(image):
    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Detect corners using Shi-Tomasi corner detection
    corners = cv2.goodFeaturesToTrack(gray, maxCorners=100, qualityLevel=0.01, minDistance=10)

    # Convert corners to integers
    corners = np.int0(corners)

    # Draw circles around detected corners
    for corner in corners:
        x, y = corner.ravel()
        cv2.circle(image, (x, y), 3, (0, 0, 255), -1)

    return image

def detect_and_match_sift(template, screenshot):
    # Convert images to grayscale
    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)
    screenshot_gray = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)
    
    # Initialize SIFT detector
    sift = cv2.SIFT_create()

    # Detect and compute key points and descriptors
    kp1, des1 = sift.detectAndCompute(template_gray, None)
    kp2, des2 = sift.detectAndCompute(screenshot_gray, None)

    # Initialize a FLANN-based matcher
    flann = cv2.FlannBasedMatcher()

    # Match descriptors
    matches = flann.knnMatch(des1, des2, k=2)

    # Filter matches using ratio test
    good_matches = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)

    # Draw matches
    matched_image = cv2.drawMatches(template, kp1, screenshot, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

    return matched_image

